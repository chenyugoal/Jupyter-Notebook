{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's next?\n",
    "\n",
    "To practice python coding and also compare ProgLearn with other algorithms\n",
    "- The hyper parameters\n",
    "- Run on Neural Networks\n",
    "- Run on Random Forests\n",
    "- Run on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #read path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from joblib import Parallel, delayed #computing efficiency\n",
    "from itertools import product #form iterable\n",
    "\n",
    "import librosa #process audio\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.listdir('D:/Python Exploration/free-spoken-digit-dataset/recordings')\n",
    "\n",
    "data=[]\n",
    "for i in file:\n",
    "    x , sr = librosa.load('D:/Python Exploration/free-spoken-digit-dataset/recordings/'+i)\n",
    "    data.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6571,)\n",
      "(13029,)\n"
     ]
    }
   ],
   "source": [
    "# notice the difference in audio length (time)\n",
    "\n",
    "print(data[0].shape)\n",
    "print(data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1982e7da640>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example STFT plot (audio_1, number_0)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "X = librosa.stft(data[0])\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz') \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prepatration -X\n",
    "# STFT of each audio is compressed into 1-D\n",
    "# 1 * 1025\n",
    "\n",
    "X=[]\n",
    "for i in range(len(data)):\n",
    "    X.append(abs(librosa.stft(data[i]).mean(axis = 1).T))\n",
    "X= np.array(X)\n",
    "#X.shape #(3000, 1025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9\n",
       "0     1  0  0  0  0  0  0  0  0  0\n",
       "1     1  0  0  0  0  0  0  0  0  0\n",
       "2     1  0  0  0  0  0  0  0  0  0\n",
       "3     1  0  0  0  0  0  0  0  0  0\n",
       "4     1  0  0  0  0  0  0  0  0  0\n",
       "...  .. .. .. .. .. .. .. .. .. ..\n",
       "2995  0  0  0  0  0  0  0  0  0  1\n",
       "2996  0  0  0  0  0  0  0  0  0  1\n",
       "2997  0  0  0  0  0  0  0  0  0  1\n",
       "2998  0  0  0  0  0  0  0  0  0  1\n",
       "2999  0  0  0  0  0  0  0  0  0  1\n",
       "\n",
       "[3000 rows x 10 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Prepatration -Y\n",
    "\n",
    "y = [i[0] for i in file]\n",
    "Y = pd.get_dummies(y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset 75% training/25% testing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_RandomForest:  0.648\n"
     ]
    }
   ],
   "source": [
    "y=np.array(list(map(int,y)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "Y_predict = clf.predict(X_test)\n",
    "accuracy=accuracy_score(Y_predict,y_test)\n",
    "print('Accuracy_RandomForest: ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following Tutorial: Label Shuffle Experiment for Progressive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data for proglearn\n",
    "\n",
    "data_x = X\n",
    "data_y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1025)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_per_task = 300\n",
    "shifts = 2 \n",
    "num_slots = int(10)\n",
    "slot_fold = range(10) \n",
    "\n",
    "n_trees=[10] # Number of trees in UF\n",
    "shift_fold = range(1,shifts,1) # Number of shifts\n",
    "\n",
    "iterable = product(n_trees,shift_fold,slot_fold)\n",
    "\n",
    "#for i in iterable: why iterable could only be used for one time???\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Task 0 For Fold 1 For Slot 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-34c6ba6a6fb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspoken_digit_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun_parallel_exp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m df_list = Parallel(n_jobs=1,verbose=1)(\n\u001b[0m\u001b[0;32m      4\u001b[0m     delayed(run_parallel_exp)(\n\u001b[0;32m      5\u001b[0m         data_x, data_y, ntree, num_points_per_task, slot=slot, shift=shift) for ntree,shift,slot in iterable)\n",
      "\u001b[1;32mD:\\Python Exploration\\VirEnv\\progressivelearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python Exploration\\VirEnv\\progressivelearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python Exploration\\VirEnv\\progressivelearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python Exploration\\VirEnv\\progressivelearning\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python Exploration\\VirEnv\\progressivelearning\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python Exploration\\VirEnv\\progressivelearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python Exploration\\VirEnv\\progressivelearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python Exploration\\ProgLearn\\benchmarks\\spoken_digit_exp\\spoken_digit_functions.py\u001b[0m in \u001b[0;36mrun_parallel_exp\u001b[1;34m(data_x, data_y, n_trees, num_points_per_task, slot, shift)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mdata_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_points_per_task\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     )\n\u001b[1;32m---> 15\u001b[1;33m     df = label_shuffle_experiment(\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python Exploration\\ProgLearn\\benchmarks\\spoken_digit_exp\\spoken_digit_functions.py\u001b[0m in \u001b[0;36mlabel_shuffle_experiment\u001b[1;34m(train_x, train_y, test_x, test_y, ntrees, shift, slot, num_points_per_task, acorn)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;31m# Make a prediction on task 0 using the trained learner on test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mllf_task\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[1;31m# Calculate the accuracy of the task 0 predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mllf_task\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python Exploration\\VirEnv\\progressivelearning\\lib\\site-packages\\proglearn-0.0.2-py3.8.egg\\proglearn\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, task_id)\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mid\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtask\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mmapped\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \"\"\"\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python Exploration\\VirEnv\\progressivelearning\\lib\\site-packages\\proglearn-0.0.2-py3.8.egg\\proglearn\\progressive_learner.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, task_id, transformer_ids)\u001b[0m\n\u001b[0;32m    697\u001b[0m             voters) to make an inference prediction.\n\u001b[0;32m    698\u001b[0m         \"\"\"\n\u001b[1;32m--> 699\u001b[1;33m         return self.task_id_to_decider[task_id].predict(\n\u001b[0m\u001b[0;32m    700\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformer_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransformer_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m         )\n",
      "\u001b[1;32mD:\\Python Exploration\\VirEnv\\progressivelearning\\lib\\site-packages\\proglearn-0.0.2-py3.8.egg\\proglearn\\deciders.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, transformer_ids)\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mvote_overall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformer_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransformer_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvote_overall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python Exploration\\VirEnv\\progressivelearning\\lib\\site-packages\\proglearn-0.0.2-py3.8.egg\\proglearn\\deciders.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, transformer_ids)\u001b[0m\n\u001b[0;32m    174\u001b[0m                 \u001b[0mX_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[0mvoter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_id_to_voters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtransformer_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbag_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m                 \u001b[0mvote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvoter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_transformed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m                 \u001b[0mvote_per_bag_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvote\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mvote_per_transformer_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvote_per_bag_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python Exploration\\VirEnv\\progressivelearning\\lib\\site-packages\\proglearn-0.0.2-py3.8.egg\\proglearn\\voters.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_label_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[0mnew_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvotes_per_example\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m                 \u001b[0mvotes_per_example\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvotes_per_example\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvotes_per_example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minsert\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\Python Exploration\\VirEnv\\progressivelearning\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(arr, obj, values, axis)\u001b[0m\n\u001b[0;32m   4555\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4557\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mN\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4558\u001b[0m             raise IndexError(\n\u001b[0;32m   4559\u001b[0m                 \u001b[1;34m\"index %i is out of bounds for axis %i with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "from spoken_digit_functions import run_parallel_exp\n",
    "\n",
    "df_list = Parallel(n_jobs=1,verbose=1)(\n",
    "    delayed(run_parallel_exp)(\n",
    "        data_x, data_y, ntree, num_points_per_task, slot=slot, shift=shift) for ntree,shift,slot in iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btes = calc_bte(df_list, num_slots, shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bte(btes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "\n",
    "'''\n",
    "total_task=10\n",
    "shift = 1\n",
    "\n",
    "x = data_x.copy()\n",
    "y = data_y.copy()\n",
    "idx = [np.where(data_y == u)[0] for u in np.unique(data_y)]\n",
    "\n",
    "batch_per_task = 10\n",
    "sample_per_class = 30\n",
    "\n",
    "for task in range(total_task):\n",
    "    print('task:',task)####\n",
    "    for batch in range(batch_per_task):\n",
    "        print('batch:',batch)####\n",
    "        for class_no in range(task, (task + 1), 1):\n",
    "            print('class_no:',class_no)####\n",
    "            indx = np.roll(idx[class_no], (shift - 1) * 10)\n",
    "            print('indx: ',indx)\n",
    "            print('shape: ',indx.shape)\n",
    "            #print(indx[400:410])\n",
    "            \n",
    "            if batch == 0 and class_no == 0 and task == 0:\n",
    "                train_x = x[\n",
    "                    indx[batch * sample_per_class : (batch + 1) * sample_per_class]\n",
    "                ]\n",
    "                test_x = x[\n",
    "                    indx[\n",
    "                        batch * total_task : (batch + 1) * total_task\n",
    "                        \n",
    "                    ]\n",
    "                ]\n",
    "                train_y = np.random.randint(\n",
    "                    low=0, high=total_task, size=sample_per_class\n",
    "                )\n",
    "                test_y = np.random.randint(low=0, high=total_task, size=total_task)\n",
    "                print('train_x: ',train_x)########\n",
    "                print(train_x.shape)########\n",
    "                print('test_x: ',test_x)#########\n",
    "                print(test_x.shape)#####\n",
    "                print('train_y',train_y)#####\n",
    "                print(train_y.shape)#########\n",
    "            else:\n",
    "                train_x = np.concatenate(\n",
    "                    (\n",
    "                        train_x,\n",
    "                        x[\n",
    "                            indx[\n",
    "                                batch\n",
    "                                * sample_per_class : (batch + 1)\n",
    "                                * sample_per_class\n",
    "                            ]\n",
    "                        ],\n",
    "                    ),\n",
    "                    axis=0,\n",
    "                )\n",
    "                test_x = np.concatenate(\n",
    "                    (\n",
    "                        test_x,\n",
    "                        x[\n",
    "                            indx[\n",
    "                                batch * total_task: (batch + 1) * total_task\n",
    "                        \n",
    "                            ]\n",
    "                        ],\n",
    "                    ),\n",
    "                    axis=0,\n",
    "                )\n",
    "                if task == 0:\n",
    "                    train_y = np.concatenate(\n",
    "                        (\n",
    "                            train_y,\n",
    "                            y[\n",
    "                                indx[\n",
    "                                    batch\n",
    "                                    * sample_per_class : (batch + 1)\n",
    "                                    * sample_per_class\n",
    "                                ]\n",
    "                            ],\n",
    "                        ),\n",
    "                        axis=0,\n",
    "                    )\n",
    "                    test_y = np.concatenate(\n",
    "                        (\n",
    "                            test_y,\n",
    "                            y[\n",
    "                                indx[\n",
    "                                    batch * total_task: (batch + 1) * total_task\n",
    "                            \n",
    "                                ]\n",
    "                            ],\n",
    "                        ),\n",
    "                        axis=0,\n",
    "                    )\n",
    "                else:\n",
    "                    train_y = np.concatenate(\n",
    "                        (\n",
    "                            train_y,\n",
    "                            np.random.randint(\n",
    "                                low=0, high=total_task, size=sample_per_class\n",
    "                            ),\n",
    "                        ),\n",
    "                        axis=0,\n",
    "                    )\n",
    "                    test_y = np.concatenate(\n",
    "                        (\n",
    "                            test_y,\n",
    "                            np.random.randint(\n",
    "                                low=0, high=total_task, size=total_task\n",
    "                            ),\n",
    "                        ),\n",
    "                        axis=0,\n",
    "                    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions copied from Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proglearn.forest import LifelongClassificationForest\n",
    "\n",
    "def run_parallel_exp(data_x, data_y, n_trees, num_points_per_task, slot=0, shift=1):\n",
    "\n",
    "    train_x, train_y, test_x, test_y = cross_val_data(\n",
    "        data_x, data_y, num_points_per_task, shift=shift\n",
    "    )\n",
    "    df = label_shuffle_experiment(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        test_x,\n",
    "        test_y,\n",
    "        n_trees,\n",
    "        shift,\n",
    "        slot,\n",
    "        num_points_per_task,\n",
    "        acorn=12345,\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def cross_val_data(data_x, data_y, num_points_per_task, shift, total_task=10):\n",
    "    x = data_x.copy()\n",
    "    y = data_y.copy()\n",
    "    idx = [np.where(data_y == u)[0] for u in np.unique(data_y)]\n",
    "\n",
    "    batch_per_task = 10\n",
    "    sample_per_class = 30\n",
    "\n",
    "    for task in range(total_task):\n",
    "        #print('task:',task)####\n",
    "        for batch in range(batch_per_task):\n",
    "            #print('batch:',batch)####\n",
    "            for class_no in range(task, (task + 1), 1):\n",
    "                #print('class_no:',class_no)####\n",
    "                indx = np.roll(idx[class_no], (shift - 1) * 10)\n",
    "                #print('indx: ',indx)\n",
    "                #print('shape: ',indx.shape)\n",
    "                #print(indx[400:410])\n",
    "\n",
    "                if batch == 0 and class_no == 0 and task == 0:\n",
    "                    train_x = x[indx[batch * sample_per_class : (batch + 1) * sample_per_class]]                    ]\n",
    "                    test_x = x[indx[batch * total_task : (batch + 1) * total_task]]\n",
    "                    train_y = np.random.randint(low=0, high=total_task, size=sample_per_class)\n",
    "                    test_y = np.random.randint(low=0, high=total_task, size=total_task)\n",
    "                    #print('train_x: ',train_x)########\n",
    "                    #print(train_x.shape)########\n",
    "                    #print('test_x: ',test_x)#########\n",
    "                    #print(test_x.shape)#####\n",
    "                    #print('train_y',train_y)#####\n",
    "                    #print(train_y.shape)#########\n",
    "                else:\n",
    "                    train_x = np.concatenate(\n",
    "                        (\n",
    "                            train_x,\n",
    "                            x[\n",
    "                                indx[\n",
    "                                    batch\n",
    "                                    * sample_per_class : (batch + 1)\n",
    "                                    * sample_per_class\n",
    "                                ]\n",
    "                            ],\n",
    "                        ),\n",
    "                        axis=0,\n",
    "                    )\n",
    "                    test_x = np.concatenate(\n",
    "                        (\n",
    "                            test_x,\n",
    "                            x[\n",
    "                                indx[\n",
    "                                    batch * total_task: (batch + 1) * total_task\n",
    "\n",
    "                                ]\n",
    "                            ],\n",
    "                        ),\n",
    "                        axis=0,\n",
    "                    )\n",
    "                    if task == 0:\n",
    "                        train_y = np.concatenate((train_y,y[indx[batch* sample_per_class : (batch + 1)                                * sample_per_class\n",
    "                                    ]\n",
    "                                ]#,\n",
    "                            ),\n",
    "                            axis=0#,\n",
    "                        )\n",
    "                        test_y = np.concatenate(\n",
    "                            (\n",
    "                                test_y,\n",
    "                                y[\n",
    "                                    indx[\n",
    "                                        batch * total_task: (batch + 1) * total_task\n",
    "\n",
    "                                    ]\n",
    "                                ]#,\n",
    "                            ),\n",
    "                            axis=0#,\n",
    "                        )\n",
    "                    else:\n",
    "                        train_y = np.concatenate(\n",
    "                            (\n",
    "                                train_y,\n",
    "                                np.random.randint(\n",
    "                                    low=0, high=total_task, size=sample_per_class\n",
    "                                )#,\n",
    "                            ),\n",
    "                            axis=0#,\n",
    "                        )\n",
    "                        test_y = np.concatenate(\n",
    "                            (\n",
    "                                test_y,\n",
    "                                np.random.randint(\n",
    "                                    low=0, high=total_task, size=total_task\n",
    "                                )#,\n",
    "                            ),\n",
    "                            axis=0#,\n",
    "                        )\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "def label_shuffle_experiment(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    test_x,\n",
    "    test_y,\n",
    "    ntrees,\n",
    "    shift,\n",
    "    slot,\n",
    "    num_points_per_task,\n",
    "    acorn=None,\n",
    "):\n",
    "\n",
    "    # We initialize lists to store the results\n",
    "    df = pd.DataFrame()\n",
    "    shifts = []\n",
    "    accuracies_across_tasks = []\n",
    "\n",
    "    # Declare the progressive learner model (L2F), with ntrees as a parameter\n",
    "    learner = LifelongClassificationForest(n_estimators=ntrees)\n",
    "\n",
    "    for task_ii in range(10):\n",
    "        print(\"Starting Task {} For Fold {} For Slot {}\".format(task_ii, shift, slot))\n",
    "        if acorn is not None:\n",
    "            np.random.seed(acorn)\n",
    "\n",
    "        # If task number is 0, add task. Else, add a transformer for the task\n",
    "        if task_ii == 0:\n",
    "            learner.add_task(\n",
    "                X=train_x[\n",
    "                    task_ii * 5000\n",
    "                    + slot * num_points_per_task : task_ii * 5000\n",
    "                    + (slot + 1) * num_points_per_task\n",
    "                ],\n",
    "                y=train_y[\n",
    "                    task_ii * 5000\n",
    "                    + slot * num_points_per_task : task_ii * 5000\n",
    "                    + (slot + 1) * num_points_per_task\n",
    "                ],\n",
    "                task_id=0,\n",
    "            )\n",
    "        else:\n",
    "            learner.add_transformer(\n",
    "                X=train_x[\n",
    "                    task_ii * 5000\n",
    "                    + slot * num_points_per_task : task_ii * 5000\n",
    "                    + (slot + 1) * num_points_per_task\n",
    "                ],\n",
    "                y=train_y[\n",
    "                    task_ii * 5000\n",
    "                    + slot * num_points_per_task : task_ii * 5000\n",
    "                    + (slot + 1) * num_points_per_task\n",
    "                ],\n",
    "            )\n",
    "\n",
    "        # Make a prediction on task 0 using the trained learner on test data\n",
    "        llf_task = learner.predict(test_x[:1000], task_id=0)\n",
    "\n",
    "        # Calculate the accuracy of the task 0 predictions\n",
    "        acc = np.mean(llf_task == test_y[:1000])\n",
    "        accuracies_across_tasks.append(acc)\n",
    "        shifts.append(shift)\n",
    "\n",
    "        print(\"Accuracy Across Tasks: {}\".format(accuracies_across_tasks))\n",
    "\n",
    "    df[\"data_fold\"] = shifts\n",
    "    df[\"task\"] = range(1, 11)\n",
    "    df[\"task_1_accuracy\"] = accuracies_across_tasks\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def calc_bte(df_list, slots, shifts):\n",
    "    shifts = shifts - 1\n",
    "    reps = slots * shifts\n",
    "    btes = np.zeros((1, 10), dtype=float)\n",
    "\n",
    "    bte_tmp = [[] for _ in range(reps)]\n",
    "\n",
    "    count = 0\n",
    "    for shift in range(shifts):\n",
    "        for slot in range(slots):\n",
    "\n",
    "            # Get the dataframe containing the accuracies for the given shift and slot\n",
    "            multitask_df = df_list[slot + shift * slots]\n",
    "            err = []\n",
    "\n",
    "            for ii in range(10):\n",
    "                err.extend(\n",
    "                    1\n",
    "                    - np.array(\n",
    "                        multitask_df[multitask_df[\"task\"] == ii + 1][\"task_1_accuracy\"]\n",
    "                    )\n",
    "                )\n",
    "            # Calculate the bte from task 1 error\n",
    "            bte = get_bte(err)\n",
    "\n",
    "            bte_tmp[count].extend(bte)\n",
    "            count += 1\n",
    "\n",
    "        # Calculate the mean backwards transfer efficiency\n",
    "        btes[0] = np.mean(bte_tmp, axis=0)\n",
    "    return btes\n",
    "\n",
    "\n",
    "def plot_bte(btes):\n",
    "    # Initialize the plot and color\n",
    "    clr = [\"#00008B\"]\n",
    "    c = sns.color_palette(clr, n_colors=len(clr))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "    # Plot the results\n",
    "    ax.plot(np.arange(1, 11), btes[0], c=c[0], label=\"L2F\", linewidth=3)\n",
    "\n",
    "    # Format the plot, and show result\n",
    "    ax.set_yticks([0.9, 0.95, 1, 1.05, 1.1, 1.15, 1.2])\n",
    "    ax.set_xticks(np.arange(1, 11))\n",
    "    ax.tick_params(labelsize=20)\n",
    "    ax.set_xlabel(\"Number of tasks seen\", fontsize=24)\n",
    "    ax.set_ylabel(\"Backward Transfer Efficiency\", fontsize=24)\n",
    "    ax.set_title(\"Label Shuffled CIFAR\", fontsize=24)\n",
    "    ax.hlines(1, 1, 10, colors=\"grey\", linestyles=\"dashed\", linewidth=1.5)\n",
    "    right_side = ax.spines[\"right\"]\n",
    "    right_side.set_visible(False)\n",
    "    top_side = ax.spines[\"top\"]\n",
    "    top_side.set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), fontsize=22)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trivial code (test first met code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees=[10]\n",
    "shift_fold = range(1,2,1)\n",
    "slot_fold = range(10)\n",
    "\n",
    "iterable = product(n_trees,shift_fold,slot_fold)\n",
    "for i in iterable:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the dataset\n",
    "# 5 speakers * 10 digit * 50 times = 2500 total number\n",
    "\n",
    "ds, info = tfds.load('spoken_digit', split='train', with_info=True) #only have split train\n",
    "tfds.as_dataframe(ds.take(3), info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for sample in ds:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for sample in ds:\n",
    "    #audio = sample['audio']\n",
    "    print(sample['audio/filename'])\n",
    "    i += 1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in ds:\n",
    "    audio = sample['audio']\n",
    "audio.shape\n",
    "\n",
    "#test_x = np.array([np.array(sample['audio']) for sample in ds],dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3],[2,4,6]])\n",
    "X[0,2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "progressivelearning",
   "language": "python",
   "name": "progressivelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
